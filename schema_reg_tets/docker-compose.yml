version: '3.7'

services:

  producer-app:
    build: .
    depends_on:
      - kafka_broker
      - schemaregistry0
    #ports:
     # - "4001:8081"
    volumes:
      - ./:/home
    networks:
      - kafka_network
      #- default

  zookeeper:
    image: 'zookeeper'
    ports:
      - "2181:2181"
    environment:
      - ZOOKEPER_CLIENT_PORT=${ZOOKEPER_CLIENT_PORT}
      - ZOOKEPER_SERVER_ID=${ZOOKEPER_SERVER_ID}
      - ZOOKEPER_SERVERS=zookeeper:2888:2888
    networks:
      - kafka_network
      - default

  kafka_broker:
    image: confluentinc/cp-kafka
    container_name: kafka_broker
    hostname: kafka_broker
    depends_on:
      - zookeeper
    environment:
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}
      - KAFKA_INTER_BROKER_LISTENER_NAME=${KAFKA_INTER_BROKER_LISTENER_NAME}
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LOG4J_LOGGERS=${KAFKA_LOG4J_LOGGERS}
      - KAFKA_AUTHORIZER_CLASS_NAME=${KAFKA_AUTHORIZER_CLASS_NAME}
      - KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND=${KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND}
      - KAFKA_BROKER_ID=1
      - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka_broker:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1  
      - KAKFA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
    networks:
      - kafka_network
      #- default

  schemaregistry0:
    image: confluentinc/cp-schema-registry:7.2.1
    hostname: schemaregistry0
    ports:
      - 8084:8085
    depends_on:
      - kafka_broker
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka_broker:19092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry0
      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry0:8085
      #SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8085

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
    networks:
      - kafka_network
     # - default

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui
    ports:
      - 8888:8080
    depends_on:
      - kafka_broker
      - schemaregistry0
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka_broker:19092
      - KAFKA_CLUSTERS_0_SCHEMAREGISTRY=http://schemaregistry0:8085
      - DYNAMIC_CONFIG_ENABLED=true
    networks:
      - kafka_network
      #- default

  # Apache Spark Master Node
  spark-master:
    image: docker.io/bitnami/spark:3.5.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '8080:8080'
    networks:
     # - default
      - kafka_network
    volumes:
      - ./:/home
      - spark_data:/opt/bitnami/spark/data
   # extra_hosts:
    #   - "host.docker.internal:172.17.0.1"

  spark-worker:
    image: docker.io/bitnami/spark:3.5.0
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      #- default
      - kafka_network
    
#volumes for data
volumes:
  spark_data:

#Network for Kafka
networks:
  kafka_network:
    driver: bridge
  default:
    external: true
    name: docker_kafka_streaming  


    #spark/172.20.0.4:7077